{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5867d637-a233-4fa7-b9cc-cd80fc6a7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import hydrobm\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from hydrobm.calculate import calc_bm\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9adee2d-63d3-492d-bea0-aed6017499ec",
   "metadata": {},
   "source": [
    "### Description\n",
    "_________________\n",
    "This script requires data for precipitation, temperature, observed streamflow, simulated streamflow, subbasin order (for calculating upstream precipitation), and subbasin IDs. This script generates the timeseries for each HydroBM benchmark by iterating through a list of IDs. It then computes the skill score between the model simulated timeseries and benchmark timeseries for each benchmark.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec66c4f-a392-4d9c-a083-4d96ee6be103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file paths\n",
    "\n",
    "pobs= '../SMM_Models/hype/model/v10_model/final_model/hds_v3/Pobs.txt' # precipitation for each subbasin\n",
    "\n",
    "tobs= '../SMM_Models/hype/model/v10_model/final_model/hds_v3/Tobs.txt' # temperature for each subbasin\n",
    "\n",
    "qobs= '../SMM_Models/hype/model/v10_model/final_model/hds_v3/Qobs.txt' # observed flow for each analyzed subbasin\n",
    "\n",
    "#cout = '../SMM_Models/hype/model/v10_model/final_model/hds_v3/results/timeCOUT_DD.txt' # simulated flow at each subbasin\n",
    "\n",
    "cout = 'inputs/raven_streamflow.csv'\n",
    "\n",
    "geodata= '../SMM_Models/hype/model/v10_model/final_model/hds_v3/GeoData.txt' # subbasin downstream order\n",
    "\n",
    "gauge_info= 'inputs/gauge_info.csv' # list of subbasins to iterate through\n",
    "\n",
    "output_dir= './' # output directory\n",
    "\n",
    "# Define skill score calculation\n",
    "skill_score_metric = 'nse' # method of skill score, options are rmse and nse\n",
    "\n",
    "start_date = \"1980-10-01\"\n",
    "end_date = \"2015-09-30\"\n",
    "\n",
    "\n",
    "# Define calibration and validation periods\n",
    "calibration_ranges = [('1980-10-01', '1984-09-30'),\n",
    "               ('1989-10-01', '1998-09-30'),\n",
    "               ('2003-10-01', '2007-09-30'),\n",
    "               ('2012-10-01', '2015-09-30')]\n",
    "\n",
    "validation_ranges = [('1984-10-01', '1989-09-30'),\n",
    "               ('1998-10-01', '2003-09-30'),\n",
    "               ('2007-10-01', '2012-09-30')]\n",
    "\n",
    "\n",
    "# Specify the benchmarks and metrics to calculate\n",
    "benchmarks = [\n",
    "        # Streamflow benchmarks\n",
    "        \"mean_flow\",\n",
    "        \"median_flow\",\n",
    "        \"annual_mean_flow\",\n",
    "        \"annual_median_flow\",\n",
    "        \"monthly_mean_flow\",\n",
    "        \"monthly_median_flow\",\n",
    "        \"daily_mean_flow\",\n",
    "        \"daily_median_flow\",\n",
    "\n",
    "        # Long-term rainfall-runoff ratio benchmarks\n",
    "        \"rainfall_runoff_ratio_to_all\",\n",
    "        \"rainfall_runoff_ratio_to_annual\",\n",
    "        \"rainfall_runoff_ratio_to_monthly\",\n",
    "        \"rainfall_runoff_ratio_to_daily\",\n",
    "        \"rainfall_runoff_ratio_to_timestep\",\n",
    "\n",
    "         # Short-term rainfall-runoff ratio benchmarks\n",
    "        \"monthly_rainfall_runoff_ratio_to_monthly\",\n",
    "        \"monthly_rainfall_runoff_ratio_to_daily\",\n",
    "        \"monthly_rainfall_runoff_ratio_to_timestep\",\n",
    "\n",
    "        # Schaefli & Gupta (2007) benchmarks\n",
    "        \"scaled_precipitation_benchmark\",  # equivalent to \"rainfall_runoff_ratio_to_daily\"\n",
    "        \"adjusted_precipitation_benchmark\",\n",
    "        \"adjusted_smoothed_precipitation_benchmark\",\n",
    "     ]\n",
    "\n",
    "# Define periods for skill score calculation and corresponding masks\n",
    "periods = {\n",
    "    'calibration': 'cal_mask',\n",
    "    'validation': 'val_mask',\n",
    "    'all': None  # No mask for 'all'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5cbd0-0fd4-44d7-a06e-fcdd4b693fd2",
   "metadata": {},
   "source": [
    "### Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c59afb-289f-4c55-987c-4125715749f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# =============================\n",
    "# Process data\n",
    "\n",
    "# Read data\n",
    "pobs= pd.read_csv(pobs, index_col=0, sep='\\t') \n",
    "tobs= pd.read_csv(tobs, index_col=0, sep='\\t') \n",
    "qobs= pd.read_csv(qobs, index_col=0, sep='\\t') \n",
    "#cout= pd.read_csv(cout, index_col=0, sep='\\t', skiprows=1) \n",
    "cout= pd.read_csv(cout, index_col=0) \n",
    "geodata= pd.read_csv(geodata, index_col=0, sep='\\t') \n",
    "gauge_info= pd.read_csv(gauge_info, index_col=1)\n",
    "\n",
    "# convert index to datetime\n",
    "pobs.index = pd.to_datetime(pobs.index)\n",
    "tobs.index = pd.to_datetime(tobs.index)\n",
    "qobs.index = pd.to_datetime(qobs.index)\n",
    "cout.index = pd.to_datetime(cout.index)\n",
    "\n",
    "# Set index to int\n",
    "geodata.index = geodata.index.astype(int)\n",
    "gauge_info.index = gauge_info.index.astype(int)\n",
    "\n",
    "# Convert column headers to integers\n",
    "pobs.columns = pobs.columns.astype(int)\n",
    "tobs.columns = tobs.columns.astype(int)\n",
    "qobs.columns = qobs.columns.astype(int)\n",
    "cout.columns = cout.columns.astype(int)\n",
    "\n",
    "# trim to match start and end dates\n",
    "pobs = pobs.loc[start_date:end_date]\n",
    "tobs = tobs.loc[start_date:end_date]\n",
    "qobs = qobs.loc[start_date:end_date]\n",
    "cout = cout.loc[start_date:end_date]\n",
    "\n",
    "# Convert the calibration and validation ranges to Pandas Timestamps\n",
    "calibration_ranges = [(pd.Timestamp(start), pd.Timestamp(end)) for start, end in calibration_ranges]\n",
    "validation_ranges = [(pd.Timestamp(start), pd.Timestamp(end)) for start, end in validation_ranges]\n",
    "\n",
    "# replace missing values with nan in streamflow\n",
    "qobs.replace(-9999, np.nan, inplace=True)\n",
    "\n",
    "# =======================\n",
    "# Create upstream to downstream digraph\n",
    "riv_graph = nx.DiGraph()\n",
    "\n",
    "# Add edges from DataFrame\n",
    "for idx, row in geodata.iterrows():\n",
    "    if row['maindown'] != '0':  # Skip if maindown is '0'\n",
    "        riv_graph.add_edge(idx, row['maindown'])\n",
    "\n",
    "# =======================\n",
    "# Convert precipitation to m3\n",
    "        \n",
    "# Set area column to numeric\n",
    "geodata['area'] = pd.to_numeric(geodata['area'])\n",
    "\n",
    "# Create dictionary with subbasin ID and area\n",
    "area_dict = geodata['area'].to_dict()\n",
    "\n",
    "# Convert pobs from mm to m\n",
    "pobs= pobs / 1000 # mm to m\n",
    "\n",
    "# Multiply each column in pobs by the corresponding area value in area_dict to get m3\n",
    "for col in pobs.columns:\n",
    "    if col in area_dict:\n",
    "        pobs[col] *= area_dict[col]\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# Test case\n",
    "gauge_info = gauge_info.loc[[58308]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256791ef-cb36-477d-b5f0-99d4c4ef016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Define calibration periods\n",
    "# # calibration_ranges = [\n",
    "# #     ('1981-10-01', '2015-09-30')\n",
    "# # ]\n",
    "\n",
    "# # Functions for KGE and NSE\n",
    "# def compute_kge(simulated, observed):\n",
    "#     simulated = np.asarray(simulated, dtype=float)\n",
    "#     observed = np.asarray(observed, dtype=float)\n",
    "#     mask = ~np.isnan(simulated) & ~np.isnan(observed)\n",
    "#     simulated, observed = simulated[mask], observed[mask]\n",
    "#     if len(simulated) == 0 or len(observed) == 0:\n",
    "#         return np.nan\n",
    "#     mean_obs, mean_sim = np.mean(observed), np.mean(simulated)\n",
    "#     std_obs, std_sim = np.std(observed), np.std(simulated)\n",
    "#     if mean_obs == 0 or std_obs == 0 or std_sim == 0:\n",
    "#         return np.nan\n",
    "#     r = np.corrcoef(observed, simulated)[0, 1]\n",
    "#     beta, gamma = mean_sim / mean_obs, std_sim / std_obs\n",
    "#     if np.isnan(r) or np.isnan(beta) or np.isnan(gamma):\n",
    "#         return np.nan\n",
    "#     return 1 - np.sqrt((r - 1)**2 + (gamma - 1)**2 + (beta - 1)**2)\n",
    "\n",
    "# def compute_nse(simulated, observed):\n",
    "#     simulated = np.asarray(simulated, dtype=float)\n",
    "#     observed = np.asarray(observed, dtype=float)\n",
    "#     mask = ~np.isnan(simulated) & ~np.isnan(observed)\n",
    "#     simulated, observed = simulated[mask], observed[mask]\n",
    "#     if len(simulated) == 0 or len(observed) == 0:\n",
    "#         return np.nan\n",
    "#     return 1 - np.sum((observed - simulated)**2) / np.sum((observed - np.mean(observed))**2)\n",
    "\n",
    "# # Loop through all columns\n",
    "# results = []\n",
    "# for col in qobs.columns:\n",
    "#     qobs_col = qobs[col]\n",
    "#     cout_col = cout[col]\n",
    "    \n",
    "#     df_pair = pd.DataFrame({'qobs': qobs_col, 'cout': cout_col})\n",
    "    \n",
    "#     # Keep only rows within any calibration period\n",
    "#     mask = pd.Series(False, index=df_pair.index)\n",
    "#     for start, end in calibration_ranges:\n",
    "#         mask |= (df_pair.index >= pd.to_datetime(start)) & (df_pair.index <= pd.to_datetime(end))\n",
    "    \n",
    "#     df_calib = df_pair[mask].dropna()\n",
    "    \n",
    "#     kge = compute_kge(df_calib['cout'], df_calib['qobs'])\n",
    "#     nse = compute_nse(df_calib['cout'], df_calib['qobs'])\n",
    "    \n",
    "#     results.append({'subbasin': col, 'KGE': kge, 'NSE': nse})\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d0d22fb-5e29-4aa2-827c-b83817896014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KGE function\n",
    "def compute_kge(simulated, observed):\n",
    "    \"\"\"\n",
    "    Computes KGE (Kling-Gupta Efficiency) between observed and simulated values.\n",
    "    \"\"\"\n",
    "    simulated = np.asarray(simulated, dtype=float)\n",
    "    observed = np.asarray(observed, dtype=float)\n",
    "\n",
    "    # Drop NaNs pairwise\n",
    "    mask = ~np.isnan(simulated) & ~np.isnan(observed)\n",
    "    simulated = simulated[mask]\n",
    "    observed = observed[mask]\n",
    "\n",
    "    if len(simulated) == 0 or len(observed) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    mean_obs = np.mean(observed)\n",
    "    mean_sim = np.mean(simulated)\n",
    "    std_obs = np.std(observed)\n",
    "    std_sim = np.std(simulated)\n",
    "\n",
    "    if mean_obs == 0 or std_obs == 0:  # avoid div by zero in ratios or corr\n",
    "        return np.nan\n",
    "\n",
    "    # Correlation (only if both series have variability)\n",
    "    if std_obs > 0 and std_sim > 0:\n",
    "        r = np.corrcoef(observed, simulated)[0, 1]\n",
    "    else:\n",
    "        r = np.nan\n",
    "\n",
    "    # print(r)\n",
    "\n",
    "    beta = mean_sim / mean_obs\n",
    "    gamma = std_sim / std_obs\n",
    "\n",
    "    if np.isnan(r) or np.isnan(beta) or np.isnan(gamma):\n",
    "        return np.nan\n",
    "\n",
    "    kge = 1 - np.sqrt((r - 1) ** 2 + (gamma - 1) ** 2 + (beta - 1) ** 2)\n",
    "    return kge\n",
    "\n",
    "    \n",
    "\n",
    "# Define funciton for calculating skill scores\n",
    "def calculate_skill_score(observed: pd.Series, simulated: pd.Series, benchmark: pd.Series, method: str ) -> float:\n",
    "    \"\"\"\n",
    "    Calculate skill score based on NSE (sum of squared errors) or RMSE.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    observed : pd.Series\n",
    "        Observed values.\n",
    "    simulated : pd.Series\n",
    "        Simulated values.\n",
    "    benchmark : pd.Series\n",
    "        Benchmark values to compare against.\n",
    "    method : str, optional\n",
    "        Skill score method: 'nse' (default) or 'rmse'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Skill score. Returns np.nan if benchmark error is zero.\n",
    "    \"\"\"\n",
    "    if method.lower() == 'nse':\n",
    "        # NSE-based: sum of squared errors\n",
    "        se_sim = ((observed - simulated) ** 2).sum()\n",
    "        se_bm = ((observed - benchmark) ** 2).sum()\n",
    "        skill_score = 1 - se_sim / se_bm if se_bm != 0 else np.nan\n",
    "\n",
    "    elif method.lower() == 'rmse':\n",
    "        # RMSE-based: root mean squared error\n",
    "        rmse_sim = np.sqrt(((observed - simulated) ** 2).mean())\n",
    "        rmse_bm = np.sqrt(((observed - benchmark) ** 2).mean())\n",
    "        skill_score = 1 - rmse_sim / rmse_bm if rmse_bm != 0 else np.nan\n",
    "\n",
    "    elif method.lower() == 'kge':\n",
    "        # KGE-based\n",
    "        kge_sim = compute_kge(simulated, observed)\n",
    "        kge_bm = compute_kge(benchmark, observed)\n",
    "\n",
    "        # print(kge_sim)\n",
    "        # print(kge_bm)\n",
    "    \n",
    "        # Return NaN if either KGE is undefined or benchmark is exactly 1\n",
    "        if np.isnan(kge_sim) or np.isnan(kge_bm) or kge_bm == 1:\n",
    "            return np.nan\n",
    "\n",
    "        skill_score = (kge_sim - kge_bm) / (1 - kge_bm)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose 'nse', 'rmse' or 'kge'.\")\n",
    "\n",
    "    return skill_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bc2ec8-7bfd-4824-91d6-8c3e64677767",
   "metadata": {},
   "source": [
    "### Calculate Skill Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e951369e-40dc-458b-bb3d-aee3ea48bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Subbasin 58308\n",
      "               streamflow  precipitation  temperature  cal_mask  val_mask\n",
      "1980-10-01  174878.893440   16012.846726     9.355536      True     False\n",
      "1980-10-02  166733.849088    6592.350027     8.910000      True     False\n",
      "1980-10-03  154755.842688       0.000000    12.566250      True     False\n",
      "1980-10-04  145412.997696    3040.901875    15.453571      True     False\n",
      "1980-10-05  139184.434368       0.000000    13.476786      True     False\n",
      "...                   ...            ...          ...       ...       ...\n",
      "2015-09-26   91991.089152  695524.278448    13.944643      True     False\n",
      "2015-09-27   98459.212608    2485.016153     8.041429      True     False\n",
      "2015-09-28   96303.171456   67859.539782     6.563571      True     False\n",
      "2015-09-29   91991.089152   12640.563406     9.423571      True     False\n",
      "2015-09-30   95105.370816   34844.138001    11.083750      True     False\n",
      "\n",
      "[12783 rows x 5 columns]\n",
      "Calculating Benchmarks\n",
      "WARNING: the annual_mean_flow benchmark cannot be used to predict unseen data. See docstring for details.\n",
      "WARNING: the annual_median_flow benchmark cannot be used to predict unseen data. See docstring for details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalculating Benchmarks\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Calculate the benchmarks and scores\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m benchmark_flows, scores \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_bm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbm_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Time period selection\u001b[39;49;00m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbm_input\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcal_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbm_input\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Variable names in 'data'\u001b[39;49;00m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecipitation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecipitation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreamflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstreamflow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Benchmark choices\u001b[39;49;00m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbenchmarks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmarks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimization_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrute_force\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Snow model inputs\u001b[39;49;00m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalc_snowmelt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msnowmelt_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43msnowmelt_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# ====================================\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Prepare to calculate skill scores\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Prepare observed and simulated flows as DataFrames\u001b[39;00m\n\u001b[1;32m     81\u001b[0m obs_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobserved_flow\u001b[39m\u001b[38;5;124m'\u001b[39m: qobs[subbasin] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m86400\u001b[39m})\n",
      "File \u001b[0;32m~/virtual-envs/scienv/lib/python3.11/site-packages/hydrobm/calculate.py:107\u001b[0m, in \u001b[0;36mcalc_bm\u001b[0;34m(data, cal_mask, val_mask, precipitation, streamflow, benchmarks, metrics, optimization_method, calc_snowmelt, temperature, snowmelt_threshold, snowmelt_rate)\u001b[0m\n\u001b[1;32m    103\u001b[0m benchmark_flow_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    104\u001b[0m     []\n\u001b[1;32m    105\u001b[0m )  \u001b[38;5;66;03m# list to store DataFrames of benchmark flows, merged later if multiple benchmarks are requested\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m benchmark \u001b[38;5;129;01min\u001b[39;00m benchmarks:\n\u001b[0;32m--> 107\u001b[0m     _, qbm \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_bm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprecipitation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecipitation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimization_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimization_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Create the benchmark flow for calibration period\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     benchmark_flow_list\u001b[38;5;241m.\u001b[39mappend(qbm)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Then loop over the metrics to calculate scores for each benchmark flow\u001b[39;00m\n",
      "File \u001b[0;32m~/virtual-envs/scienv/lib/python3.11/site-packages/hydrobm/benchmarks.py:919\u001b[0m, in \u001b[0;36mcreate_bm\u001b[0;34m(data, benchmark, cal_mask, precipitation, streamflow, optimization_method)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;66;03m# Equivalent to Schaefli & Gupta's (2007) simple benchmark\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# (adjusted precipitation, no lag and smoothing)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m benchmark \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrainfall_runoff_ratio_to_daily\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 919\u001b[0m     bm_vals, qbm \u001b[38;5;241m=\u001b[39m \u001b[43mbm_rainfall_runoff_ratio_to_daily\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcal_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecipitation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecipitation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreamflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamflow\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m benchmark \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrainfall_runoff_ratio_to_timestep\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    924\u001b[0m     bm_vals, qbm \u001b[38;5;241m=\u001b[39m bm_rainfall_runoff_ratio_to_timestep(\n\u001b[1;32m    925\u001b[0m         data, cal_mask, precipitation\u001b[38;5;241m=\u001b[39mprecipitation, streamflow\u001b[38;5;241m=\u001b[39mstreamflow\n\u001b[1;32m    926\u001b[0m     )\n",
      "File \u001b[0;32m~/virtual-envs/scienv/lib/python3.11/site-packages/hydrobm/benchmarks.py:424\u001b[0m, in \u001b[0;36mbm_rainfall_runoff_ratio_to_daily\u001b[0;34m(data, cal_mask, precipitation, streamflow)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m qbm\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m.\u001b[39munique():  \u001b[38;5;66;03m# for each year\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doy \u001b[38;5;129;01min\u001b[39;00m qbm\u001b[38;5;241m.\u001b[39mloc[\n\u001b[1;32m    422\u001b[0m         qbm\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m==\u001b[39m year\n\u001b[1;32m    423\u001b[0m     ]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mdayofyear\u001b[38;5;241m.\u001b[39munique():  \u001b[38;5;66;03m# for each DoY in index for this year (takes care of mising days)\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m         this_day \u001b[38;5;241m=\u001b[39m (data\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m==\u001b[39m year) \u001b[38;5;241m&\u001b[39m (\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdayofyear\u001b[49m \u001b[38;5;241m==\u001b[39m doy)\n\u001b[1;32m    425\u001b[0m         mean_daily_precip \u001b[38;5;241m=\u001b[39m data[precipitation]\u001b[38;5;241m.\u001b[39mloc[this_day]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    426\u001b[0m         qbm\u001b[38;5;241m.\u001b[39mloc[this_day, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbm_rainfall_runoff_ratio_to_daily\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m bm_vals \u001b[38;5;241m*\u001b[39m mean_daily_precip\n",
      "File \u001b[0;32m~/virtual-envs/scienv/lib/python3.11/site-packages/pandas/core/indexes/extension.py:68\u001b[0m, in \u001b[0;36m_inherit_from_data.<locals>.fget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, name)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)):\n",
      "File \u001b[0;32m~/virtual-envs/scienv/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:152\u001b[0m, in \u001b[0;36m_field_accessor.<locals>.f\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_mask_results(result, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfields\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_date_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_creso\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_mask_results(\n\u001b[1;32m    154\u001b[0m         result, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# Global dictionary to store skill scores for all subbasins\n",
    "all_subbasin_scores = {}\n",
    "\n",
    "# Iterate over each subbasin in list\n",
    "for subbasin in gauge_info.index:\n",
    "\n",
    "    print(f'Analyzing Subbasin {subbasin}')\n",
    "\n",
    "    # =================================\n",
    "    # Create HydroBM input\n",
    "    \n",
    "    # Find upstream segments for the given subbasin\n",
    "    upstream_segments = list(nx.ancestors(riv_graph, subbasin))\n",
    "    \n",
    "    # Add the target segment to the upstream segments\n",
    "    upstream_segments.append(subbasin)\n",
    "\n",
    "\n",
    "    # Sum upstream precipitation\n",
    "    precipitation_sum = pd.DataFrame(\n",
    "        pobs[upstream_segments].sum(axis=1),\n",
    "        columns=['precipitation']\n",
    "    )\n",
    "    \n",
    "    # Mean upstream temperature\n",
    "    temperature_mean = pd.DataFrame(\n",
    "        tobs[upstream_segments].mean(axis=1),\n",
    "        columns=['temperature']\n",
    "    )\n",
    "\n",
    "    # Create hydrobm input dataframe\n",
    "    bm_input = pd.DataFrame({\n",
    "        'streamflow': qobs[subbasin] * 84600,  # Streamflow volume for the given subbasin\n",
    "        'precipitation': precipitation_sum['precipitation'],  # Sum of upstream precipitation in m3\n",
    "        'temperature': temperature_mean['temperature'] # mean upstream temperature of the subbasin\n",
    "    })\n",
    "\n",
    "    # Create the cal_mask column\n",
    "    bm_input['cal_mask'] = bm_input.index.to_series().apply(\n",
    "        lambda x: any(pd.to_datetime(start) <= x <= pd.to_datetime(end) for start, end in calibration_ranges)\n",
    "    )\n",
    "\n",
    "    # Create the val_mask column\n",
    "    bm_input['val_mask'] = bm_input.index.to_series().apply(\n",
    "        lambda x: any(pd.to_datetime(start) <= x <= pd.to_datetime(end) for start, end in validation_ranges)\n",
    "    )\n",
    "\n",
    "    print(bm_input)\n",
    "    print('Calculating Benchmarks')\n",
    "    \n",
    "    # Calculate the benchmarks and scores\n",
    "    benchmark_flows, scores = calc_bm(\n",
    "        bm_input,\n",
    "\n",
    "        # Time period selection\n",
    "        bm_input['cal_mask'],\n",
    "        val_mask=bm_input['val_mask'],\n",
    "\n",
    "        # Variable names in 'data'\n",
    "        precipitation=\"precipitation\",\n",
    "        streamflow=\"streamflow\",\n",
    "\n",
    "        # Benchmark choices\n",
    "        benchmarks=benchmarks,\n",
    "        metrics=['nse', 'kge'],\n",
    "        optimization_method=\"brute_force\",\n",
    "\n",
    "        # Snow model inputs\n",
    "        calc_snowmelt=True,\n",
    "        temperature=\"temperature\",\n",
    "        snowmelt_threshold=0.0,\n",
    "        snowmelt_rate=3.0,\n",
    "    )\n",
    "\n",
    "    \n",
    "    # ====================================\n",
    "    # Prepare to calculate skill scores\n",
    "    \n",
    "    # Prepare observed and simulated flows as DataFrames\n",
    "    obs_df = pd.DataFrame({'observed_flow': qobs[subbasin] * 86400})\n",
    "    sim_df = pd.DataFrame({'simulated_flow': cout[subbasin] * 86400})\n",
    "\n",
    "    # Prepare cal and val masks as DataFrames\n",
    "    cal_mask_df = pd.DataFrame({'cal_mask': bm_input['cal_mask']})\n",
    "    val_mask_df = pd.DataFrame({'val_mask': bm_input['val_mask']})\n",
    "    \n",
    "    # Merge onto benchmark_flows using index\n",
    "    benchmark_flows = benchmark_flows.merge(obs_df, left_index=True, right_index=True, how='left')\n",
    "    benchmark_flows = benchmark_flows.merge(sim_df, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # Merge masks onto benchmark_flows using index\n",
    "    benchmark_flows = benchmark_flows.merge(cal_mask_df, left_index=True, right_index=True, how='left')\n",
    "    benchmark_flows = benchmark_flows.merge(val_mask_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # ======================\n",
    "    # Calculate skill scores\n",
    "\n",
    "    # Get list of benchmark columns\n",
    "    bm_columns = [col for col in benchmark_flows.columns if col.startswith('bm_')]\n",
    "\n",
    "    # Dictionary to store results\n",
    "    skill_scores = {period: {} for period in periods}\n",
    "\n",
    "    # Iterate over periods\n",
    "    for period_name, mask_col in periods.items():\n",
    "\n",
    "        print(f'Calculating Skill Score for: {period_name}')\n",
    "\n",
    "        # Trim to only required period\n",
    "        if mask_col is not None:\n",
    "            df_period = benchmark_flows[benchmark_flows[mask_col]]\n",
    "        else:\n",
    "            df_period = benchmark_flows.copy()\n",
    "            \n",
    "        \n",
    "        for bm_col in bm_columns:\n",
    "\n",
    "            # # Debug: print std deviation of benchmark column\n",
    "            # std_bm = df_period[bm_col].std()\n",
    "            # print(f\"Period={period_name}, Benchmark={bm_col}, Std={std_bm:.6f}\")\n",
    "\n",
    "            # Calculate skill score based on metric\n",
    "            skill_score = calculate_skill_score(\n",
    "                observed=df_period['observed_flow'],\n",
    "                simulated=df_period['simulated_flow'],\n",
    "                benchmark=df_period[bm_col],\n",
    "                method=skill_score_metric  # nse or rmse \n",
    "            )\n",
    "\n",
    "            # Remove benchmarks that don't work on unseen data\n",
    "            if bm_col in ['bm_annual_mean_flow', 'bm_annual_median_flow'] and period_name in ['calibration', 'validation', 'all']:\n",
    "                skill_score = np.nan\n",
    "        \n",
    "            # Store\n",
    "            skill_scores[period_name][bm_col] = skill_score\n",
    "\n",
    "    # Store subbasin results in the global dictionary\n",
    "    all_subbasin_scores[subbasin] = skill_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7b5e9-1320-439c-9643-1f09a523ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Save outputs\n",
    "\n",
    "# Convert global dictionary to a multi-index DataFrame for easy access\n",
    "skill_scores_df = pd.concat({\n",
    "    subbasin: pd.DataFrame(sub_scores) \n",
    "    for subbasin, sub_scores in all_subbasin_scores.items()\n",
    "}, names=['subbasin', 'benchmark'])\n",
    "\n",
    "# Reset MultiIndex to get subbasin and benchmark as columns\n",
    "skill_scores_long = skill_scores_df.reset_index()\n",
    "skill_scores_long = skill_scores_long.rename(columns={'level_0': 'subbasin', 'level_1': 'benchmark'})\n",
    "\n",
    "# Now, melt the periods into a single column\n",
    "skill_scores_long = skill_scores_long.melt(\n",
    "    id_vars=['subbasin', 'benchmark'],\n",
    "    value_vars=['calibration', 'validation', 'all'],\n",
    "    var_name='period',\n",
    "    value_name='skill_score'\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "output_file = os.path.join(output_dir, 'skill_scores.csv')\n",
    "skill_scores_long.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Skill scores saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9dd6b7-0fcd-47b6-827e-01e1a8c3b90e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scienv",
   "language": "python",
   "name": "scienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
